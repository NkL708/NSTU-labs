{
 "cells": [
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "71ba8645",
   "metadata": {},
   "source": [
    "### *АВТ-910_РГЗ_Безденежных_Васильев*\n",
    "\n",
    "## Цель работы\n",
    "Знакомство элементами технологии создания баз знаний интеллектуальных систем.\n",
    "\n",
    "## Задачи\n",
    "- Освоение способа сохранения и загрузки обученных моделей машинного обучения;\n",
    "- Разработка интерфейса доступа к сохраненным моделям;\n",
    "- Организация произвольных запросов с использованием разработанного интерфейса.\n",
    "\n",
    "Используемые программные инструменты:\n",
    "- Язык программирования: python\n",
    "- Реализация алгоритмов машинного обучения: tensorflow, sklearn\n",
    "- Сериализация/десериализация: json, pickle, tensorflow\n",
    "- web-интерфейс: streamlit\n",
    "\n",
    "## Ход работы \n",
    "1. Выполнить загрузку файла с подготовленным набором данных (очищенный от пропусков и выбросов для целевой и независимых переменных) в таблицу <u>исходных данных df</u>\n",
    "2. Объявить список названий целевых (target) и независимой (features) переменных\n",
    "3. Отделить X от Y исходной таблицы и сформировать новые таблицы dfX и dfY\n",
    "4. Выполнить процедуру НОРМАЛИЗАЦИИ данных и сохранить в отдельную таблиц\n",
    "    1. Используя класс MinMaxScaler создать отдельные объекты-шкалёры <u>scalerNormForX</u> и <u>scalerNormForY</u> для выполнения нормализации для целевой и независимых переменных\n",
    "    2. Используя класс MinMaxScaler получить нормализованные версии <u>dfX</u> и <u>dfY</u> и сохранить их в <u>dfXNorm</u> и <u>dfYNorm</u> соответственно\n",
    "5. Сформировать обучающую и проверочную части\n",
    "    1. На основе исходных данных <u>dfX</u> и <u>dfY</u> сформировать <u>xTrain , xTest , yTrain , yTest</u>\n",
    "    2. На основе нормализованной выборки  <u>dfXNorm</u> и <u>dfYNorm</u> сформировать <u>xNormTrain, xNormTest, yNormTrain, yNormTest</u>\n",
    "6. Модель m1. Линейная регрессия\n",
    "    1. Для построения линейной регрессионной модели выбрать из <u>dfX</u> группу  независимых признаков 'x1, x2, x3, ...'\n",
    "    2. Создать и обучить на выбранных признаках модель LinearRegression() из библиотеки sklearn, используя <u>xTrain</u>, <u>yTrain</u>\n",
    "    3. Получить вычисленные значения <u>yPred</u> с использованием обученной модели на  данных <u>xTest</u>\n",
    "    4. Получить оценки точности R2, RMSE для построенной модели, используя данные  <u>yPred</u> и <u>yTest</u>\n",
    "7. Модель m2. Нейронная сеть\n",
    "    1. Выбрать из <u>dfNormX</u> группу  независимых признаков 'x1, x2, x3, ...'\n",
    "    2. Определить\n",
    "        1. Структуру одной моделей (кол-во узлов на входных, выходных и скрытых слоях и узлов на каждом из слоев).\n",
    "        2. Вид нелинейных функции активации для скрытых слоев\n",
    "        3. Функцию оценки потерь (способ оценки ошибок между <u>yNormPred</u> и <u>yTrain</u>) \n",
    "        4. Функцию оптимизации\n",
    "    3. Создать модель, используя библиотеку tensorflow\n",
    "    4. Обучить модель на выбранных признаках, используя нормализованные данные <u>xNormTrain</u>, <u>yNormTrain</u>\n",
    "    5. Получить вычисленные значения <u>yNormPred</u> с использованием обученной модели на  нормализованных данных <u>xNormTest </u>\n",
    "    6. Получить оценки точности R2, RMSE для построенной модели, используя  нормализованные данные  <u>yNormPred</u> и <u>yNormTest</u>\n",
    "8. Сохранение моделей. Для обученных моделей (m1, m2, …):\n",
    "    1. Заполните следующие характеристики модели в структуре типа “ключ-значение”, где “ключ” название характеристики:\n",
    "        * Тип модели\n",
    "        * Требует нормализованные данные\n",
    "        * Название признаков входных\n",
    "        * Название признаков выходных\n",
    "        * R2\n",
    "        * RMSE\n",
    "        * Выбранные вами дополнительные характеристики …\n",
    "    2. Сохраните структуру типа “ключ-значение” в файле формата JSON, используя команду  json.dump(...)\n",
    "    3. Для m2 сохраните объекты-шкалеры <u>scalerNormForX</u> и <u>scalerNormForY</u> с помощью механизма сериализации в файл, используя команду  pickle.dump(...)\n",
    "    4. Сохраните обученные модели с помощью механизма сериализации в файл:\n",
    "        1. Для моделей m1 используйте команду  pickle.dump(...)\n",
    "        2. Для моделей m2 используйте команду  tensorflow.save(...)\n",
    "9. Загрузка и опрос обученных моделей в среде JupyterLab \n",
    "    1. Создайте новый файл JupyterLab  (*ipynb)\n",
    "    2. Изучите и проверьте все функции, необходимые для загрузки (десериализации) объектов\n",
    "    3. Создайте таблицу pandas.DataFrame c единственной строкой и произвольными значениями.\n",
    "    4. Проверьте работу функций fit, transform, inverse_transform у объекта шкалёра для созданной таблицы pandas.DataFrame\n",
    "    5. Проверьте работу функции вычисления ответа от обученной модели (функция predict)\n",
    "10. Разработка web-интерфейса\n",
    "    1. Для каждой из независимых (features) переменных подберите подходящий способ ввода значений из доступных в библиотеке streamlit\n",
    "    2. Создайте проект web-страницы и расположите элементы интерфейса для ввода значений независимых (features) переменных и вывода вычисленных значений целевой (target)\n",
    "11. Загрузка и опрос обученных моделей в созданном  web-интерфейсе\n",
    "    1. В созданном проекте web-страницы загрузите все объекты сохраненные в п.8 с учетом формата сохранения\n",
    "    2. Организуйте передачу введенных на web-странице значений (независимых (features) переменных) в функцию вычисления ответа у загруженных моделей\n",
    "        1. Получить введенные значения и преобразовать их в таблицу данных типа pandas.DataFrame. Таблица будет содержать единственную строку.\n",
    "        2. Создайте таблицу данных типа pandas.DataFrame с нормализованной версией введенных значений, используя объект-шкалёра <u>scalerNormForX</u>. Таблица будет содержать единственную строку.\n",
    "        3. Для получения вычисленного ответа передайте в функцию .predict(...) загруженных моделей соответствующую таблицу\n",
    "    3. Отобразите на web-странице вычисленные ответы от каждой модели. При необходимости выполните денормализацию вычисленных значений ответа с использованием объекта-шкалёра <u>scalerNormForY</u>\n",
    "    4. Отобразите на web-странице характеристики точности R2, RMSE для соответствующих моделей.\n",
    "12. Проверка работоспособности\n",
    "    1. Выберите из проверочной части xTest и yTest не менее 3 строк-образцов.\n",
    "    2. Введите значения независимых (features) переменных из строк образцов на web-странице и получите вычисленные значения ответа для каждой из них.\n",
    "    3. Полученные результаты оформите в виде таблицы в отчете\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "## Ссылки на доп материалы\n",
    "* [Офф. справка] Библиотека pickle.URL: https://docs.python.org/3/library/pickle.html \n",
    "* [Офф. справка] Библиотека json.URL: https://docs.python.org/3/library/json.html \n",
    "* [Офф. справка] TensorFlow Сохранение и загрузка моделей.URL: https://www.tensorflow.org/tutorials/keras/save_and_load\n",
    "* [Офф. справка] Streamlit. Компоненты страницы для ввода значений.URL: https://docs.streamlit.io/library/api-reference#input-widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bc5cb1",
   "metadata": {},
   "source": [
    "Импортируем все модули, требуемые для выполнения работы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "379234d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [3], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MinMaxScaler\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearRegression\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3bee95",
   "metadata": {},
   "source": [
    "Объявим функции, которые понадобятся нам в будущем несколько раз:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccd287d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GET_METRICS_SINGLE(y_test, y_pred):\n",
    "    '''\n",
    "    Вычисление и вывод метрик: MAE, RMSE, R2.\n",
    "    На основе сравнения проверочных и вычисленных.\n",
    "    :param y_test: - проверочные значения целевой переменный\n",
    "    :param y_pred: - вычисленные значения целевой переменный\n",
    "    '''\n",
    "    mae  = metrics.mean_absolute_error        (y_test, y_pred)\n",
    "    mse  = metrics.mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2   = metrics.r2_score                   (y_test, y_pred)\n",
    "\n",
    "    print (\"MAE : {:>9,.3f} (средняя абсолютная ошибка)\".format              ( mae ))\n",
    "    print (\"MSE : {:>9,.6f} (среднеквадратичная ошибка)\".format( mse ))\n",
    "    print (\"RMSE: {:>9,.6f} (кв. корень из среднеквадратичной ошибки)\".format( rmse ))\n",
    "    print (\"R2  : {:>9,.3f} (коэфф. детерминации)\".format                    ( r2 ))\n",
    "#--------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2128b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PLOT34(y_test, y_pred):\n",
    "    '''\n",
    "    Функция построения графиков\n",
    "    :param y_test: - проверочные значения целевой переменный\n",
    "    :param y_pred: - вычисленные значения целевой переменный\n",
    "    '''\n",
    "    plt.figure(figsize=(12,6))\n",
    "    # == Диаграмма рассеяния вычисленных значений ==\n",
    "    # создать первое полотно 121: 1-строк, 2-столбцов, 1-индекс текущего полотна в сетке\n",
    "    plt.subplot(121)\n",
    "    plt.scatter(y_test, y_pred,  alpha=0.1)\n",
    "    plt.scatter(y_test, y_test,  alpha=0.1)\n",
    "    plt.title('Диаграмма рассеяния вычисленных значений');\n",
    "    plt.xlabel('Проверочное Y')\n",
    "    plt.ylabel('Вычисленное Y')\n",
    "    # == Диаграмма рассеяния ошибок ==\n",
    "    # создать первое полотно 121: 1-строк, 2-столбцов, 2-индекс текущего полотна в сетке\n",
    "    plt.subplot(122)\n",
    "    plt.scatter(y_test, (y_test - y_pred)**2,  alpha=0.1)\n",
    "    plt.title('Диаграмма рассеяния квадрата абсолютной ошибки')\n",
    "    plt.xlabel('Проверочное Y')\n",
    "    plt.ylabel('Квадрат абсолютной ошибки')\n",
    "#--------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562537be",
   "metadata": {},
   "source": [
    "Загрузим файл с подготовленным набором данных из прошлых работ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c817c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./assets/datasets/var20/bike-sharing-dataset_nan_PREPARED.csv', sep=',', header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af453ed",
   "metadata": {},
   "source": [
    "Объявим список названий целевых (target) и независимой (features) переменных из наших прошлых работ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57abba60",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['weekday',  'hr', 'season', 'temp', 'weathersit']\n",
    "target = ['cnt']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed14ace",
   "metadata": {},
   "source": [
    "Отделим X от Y и сформируем новые таблицы <u>dfX</u> и <u>dfY</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346d9935",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfX = df[features]\n",
    "dfY = df[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207f59a9",
   "metadata": {},
   "source": [
    "Выполним процедуру нормализации данных и сохраним результат в 2 отдельные таблицы <u>dfXNorm</u> и <u>dfYNorm</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d30b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalerNormForX = MinMaxScaler()\n",
    "scalerNormForY = MinMaxScaler()\n",
    "\n",
    "dfXNorm = pd.DataFrame(data=scalerNormForX.fit_transform(dfX), columns=dfX.columns, index=dfX.index)\n",
    "dfYNorm = pd.DataFrame(data=scalerNormForY.fit_transform(dfY), columns=dfY.columns, index=dfY.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a497c823",
   "metadata": {},
   "source": [
    "Построим гистограммы по каждому признаку "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2053d981",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 5))\n",
    "plot_number = 0\n",
    "for feature_name in (features+target):\n",
    "    plot_number += 1\n",
    "    plt.subplot(1, len(features+target), plot_number)\n",
    "    plt.hist(df[feature_name]) # Построение гистрограммы\n",
    "    plt.title(feature_name)\n",
    "    plt.xlabel(u'Значения')\n",
    "    plt.ylabel(u'Частота')\n",
    "    print(feature_name, \n",
    "          df[feature_name].min(),\n",
    "          df[feature_name].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6b193f",
   "metadata": {},
   "source": [
    "Сформируем обучающую и проверочную части. Сначала для исходной выборки, затем для нормализованной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66dc6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_seed = 8\n",
    "valid_size = 0.3\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(\n",
    "    dfX, dfY, test_size=valid_size, random_state=rand_seed, shuffle=True)\n",
    "\n",
    "xNormTrain, xNormTest, yNormTrain, yNormTest = train_test_split(\n",
    "    dfXNorm, dfYNorm, test_size=valid_size, random_state=rand_seed, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1583b20e",
   "metadata": {},
   "source": [
    "Для построения линейной регрессионной модели выберем из dfX группу независимых признаков 'x1, x2, x3, ...'. Возьмём те же признаки, что и в прошлых ЛР."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ceb827",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "m1 = lr.fit(\n",
    "    xTrain[['season', 'temp', 'weathersit']], \n",
    "    yTrain[['cnt']]\n",
    ")\n",
    "yPred = m1.predict(xTest[['season', 'temp', 'weathersit']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c7c8a8",
   "metadata": {},
   "source": [
    "Получим оценки точности R2, RMSE для построенной модели, используя данные <u>yPred</u> и <u>yTest</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4234ad27",
   "metadata": {},
   "outputs": [],
   "source": [
    "GET_METRICS_SINGLE(yTest, yPred)\n",
    "print(f\"Линейная одномерная регрессия. Признаки 'season', 'temp', 'weathersit'.\")\n",
    "print(f'yPred (x) = x * {m1.coef_} + {m1.intercept_}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9cf7b0",
   "metadata": {},
   "source": [
    "Графики линейной регрессии:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c2b539",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.histplot(yTest[['cnt']] - yPred, color=\"red\", kde=True, stat=\"density\")\n",
    "plt.plot([0, 0], [0, 10 * pow(10,-7)], '--', lw=2, c='r')\n",
    "plt.ylabel(u'Плотность')\n",
    "plt.xlabel(u'Значение ошибки')\n",
    "plt.title(u'Плотность распределения и гистограмма ошибок');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7559a1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "m1_plot = PLOT34(yTest, yPred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23663e8",
   "metadata": {},
   "source": [
    "Сохраним числовые характеристики в отдельные переменные для будущего сохранения в файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1a039d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_r2 = metrics.r2_score(yTest, yPred)\n",
    "m1_rmse = np.sqrt(metrics.mean_squared_error(yTest, yPred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5479ad0a",
   "metadata": {},
   "source": [
    "Построим модель при помощи нейронной сети. Выберем из dfNormX группу независимых признаков 'x1, x2, x3, ...' (те же признаки, что и в 3 ЛР). Будем использовать скрытые слои."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621565ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    totalHistoryLossTrain=[]\n",
    "    totalHistoryLossTest=[]\n",
    "    input_size  = 5\n",
    "    output_size = 1\n",
    "    m2 = tf.keras.models.Sequential()\n",
    "    # Слои НС\n",
    "    m2.add(tf.keras.layers.Input(shape=(input_size)))\n",
    "    m2.add(tf.keras.layers.Dense(units=25, activation=tf.keras.activations.relu))\n",
    "    m2.add(tf.keras.layers.Dense(units=10, activation=tf.keras.activations.relu))\n",
    "    m2.add(tf.keras.layers.Dense(units=input_size, activation=tf.keras.activations.relu))\n",
    "    m2.add(tf.keras.layers.Dense(units=output_size, activation=tf.keras.activations.linear))\n",
    "    \n",
    "    fLoss = tf.keras.losses.mean_squared_error\n",
    "    fOptimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "    fMetric = [tf.keras.losses.mean_squared_error]\n",
    "    m2.compile(\n",
    "        loss=fLoss, \n",
    "        optimizer=fOptimizer, \n",
    "        metrics=[fMetric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725c37b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochForTrain = 150\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    history = m2.fit(\n",
    "        xNormTrain[['weekday',  'hr', 'season', 'temp', 'weathersit']],\n",
    "        yNormTrain,\n",
    "        validation_data=(xNormTest[['weekday',  'hr', 'season', 'temp', 'weathersit']], yNormTest),\n",
    "        epochs=epochForTrain,\n",
    "        batch_size=1000,\n",
    "        verbose=1)\n",
    "    totalHistoryLossTrain.extend(history.history['loss'])\n",
    "    if 'val_loss' in history.history.keys():\n",
    "        totalHistoryLossTest.extend(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01e2f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(totalHistoryLossTrain, label='train')\n",
    "if 'val_loss' in history.history.keys():\n",
    "    plt.plot(totalHistoryLossTest, label='test')\n",
    "plt.legend()\n",
    "plt.title(\"История изменений выбраной оценки потерь (LossVal = mean_squared_error)\")\n",
    "plt.ylabel(\"Оценка потерь (mean_squared_error)\")\n",
    "plt.xlabel(\"Эпохи обучения\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5c15be",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    yNormPred = m2.predict(xNormTest[['weekday',  'hr', 'season', 'temp', 'weathersit']])\n",
    "GET_METRICS_SINGLE(yNormTest, yNormPred)\n",
    "PLOT34(yNormTest, yNormPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5c2b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_r2 = metrics.r2_score(yNormTest, yNormPred)\n",
    "m2_rmse = np.sqrt(metrics.mean_squared_error(yNormTest, yNormPred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f7873b",
   "metadata": {},
   "source": [
    "Сохраним дополнительные данные о наших моделях в формате JSON. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00e6488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание словарей с данными о моделях\n",
    "m1_info = dict()\n",
    "m1_info['m2_type'] = str(type(m1))\n",
    "m1_info['requires_normalised_data'] = False\n",
    "m1_info['features'] = ['season', 'temp', 'weathersit']\n",
    "m1_info['target'] = target\n",
    "m1_info['R2'] = m1_r2\n",
    "m1_info['RMSE'] = m1_rmse\n",
    "\n",
    "m2_info = dict()\n",
    "m2_info['m2_type'] = str(type(m2))\n",
    "m2_info['requires_normalised_data'] = True\n",
    "m2_info['features'] = ['weekday',  'hr', 'season', 'temp', 'weathersit']\n",
    "m2_info['target'] = target\n",
    "m2_info['R2'] = m2_r2\n",
    "m2_info['RMSE'] = m2_rmse\n",
    "\n",
    "# Сохранение словарей в формате JSON\n",
    "with open(r'./assets/dump/m1_info.json', 'w', encoding='utf-8') as filestream:\n",
    "    json.dump(m1_info, filestream, indent=4)\n",
    "with open(r'./assets/dump/m2_info.json', 'w', encoding='utf-8') as filestream:\n",
    "    json.dump(m2_info, filestream, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515dd724",
   "metadata": {},
   "outputs": [],
   "source": [
    "yNormPred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401601bd",
   "metadata": {},
   "source": [
    "Сохраним модель m1 и модель m2, а также объекты-шкалёры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf39ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение объектов-шкалёров\n",
    "with open(r'./assets/dump/scalerNormForX.txt', 'wb') as f:\n",
    "    pickle.dump(scalerNormForX, f)\n",
    "with open(r'./assets/dump/scalerNormForY.txt', 'wb') as f:\n",
    "    pickle.dump(scalerNormForY, f)\n",
    "# Сохранение моделей\n",
    "with open(r'./assets/dump/m1.txt', 'wb') as f:\n",
    "    pickle.dump(m1, f)\n",
    "m2.save(r'./assets/dump/m2.h5', overwrite=True, save_format='h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af63c304",
   "metadata": {},
   "source": [
    "Загрузку наших моделей будем осуществлять уже в другом файле (RGZ-2)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
